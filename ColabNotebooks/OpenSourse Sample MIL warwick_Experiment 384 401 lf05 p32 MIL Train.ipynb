{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1_HUut4YYm5"
   },
   "source": [
    "## This is the official training script of MIL tasks\n",
    "* Use google colab pro+ (high RAM+GPU)\n",
    "* we use the P100 GPU for the Experiments\n",
    "\n",
    "## The code and Training process along with all record are private\n",
    "* Our github page: https://github.com/sagizty/MIL-SI\n",
    "* The ROSE dataset is not publicly aviliable.\n",
    "* However the MICCAI 2015 chanllenge dataset is avaliable for illustration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1651152759973,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     },
     "user_tz": -480
    },
    "id": "ZnbrNSoSXFm5",
    "outputId": "e9ff7b5d-a9bc-4ac4-8859-f79cdf90ade9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Apr 28 13:32:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1651152759973,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     },
     "user_tz": -480
    },
    "id": "n9GPOn5gcykA",
    "outputId": "d4703cda-0bb2-4e21-836e-c1890e7dd294"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Apr 28 21:32:39 UTC 2022\n"
     ]
    }
   ],
   "source": [
    "!date --date='+8 hour'  # CST time zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZKz8QDpIdj3"
   },
   "source": [
    "## Mount the Github\n",
    "get the code from Github official page\n",
    "\n",
    "ref: https://blog.csdn.net/u011119817/article/details/108722832\n",
    "ref: https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651152759974,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     },
     "user_tz": -480
    },
    "id": "2oT4q-sJIgEp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# GitHub user\n",
    "user = 'xxxxx'\n",
    "# GitHub personal-access-token (this has been revoke already, use your own)\n",
    "password = 'ghp_xxxxx'\n",
    "os.environ['GITHUB_AUTH'] = user + ':' + password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbnpeHYUgsJz"
   },
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23215,
     "status": "ok",
     "timestamp": 1651152783185,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     },
     "user_tz": -480
    },
    "id": "3obRNrIaffjK",
    "outputId": "8647dbcb-3f40-4254-ae8b-a827b9cd93cc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYevYeMFYmlx"
   },
   "source": [
    "## create file-system enviroment\n",
    "* mount your google drive first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18529,
     "status": "ok",
     "timestamp": 1651152801709,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     },
     "user_tz": -480
    },
    "id": "ePtQFcQCEPlu",
    "outputId": "2c16cf3b-fdf1-4fd0-ea35-54d46b0152eb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Folder Tree Creation completed!\n",
      "Cloning into '/home/MIL_Experiment/code'...\n",
      "remote: Enumerating objects: 639, done.\u001B[K\n",
      "remote: Counting objects: 100% (16/16), done.\u001B[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001B[K\n",
      "remote: Total 639 (delta 6), reused 0 (delta 0), pack-reused 623\u001B[K\n",
      "Receiving objects: 100% (639/639), 500.96 MiB | 50.47 MiB/s, done.\n",
      "Resolving deltas: 100% (115/115), done.\n",
      "Checking out files: 100% (453/453), done.\n",
      "code transfer from github completed!\n",
      "data transfer completed!\n"
     ]
    }
   ],
   "source": [
    "# create file-system enviroment\n",
    "# mount the google drive first\n",
    "# https://drive.google.com/drive/u/1/my-drive\n",
    "\n",
    "# clear colab path\n",
    "!rm -rf /data\n",
    "!rm -rf /home/MIL_Experiment\n",
    "\n",
    "# create path\n",
    "!mkdir /home/MIL_Experiment\n",
    "!mkdir /home/MIL_Experiment/runs\n",
    "!mkdir /home/MIL_Experiment/code\n",
    "!mkdir /home/MIL_Experiment/saved_models\n",
    "!mkdir /home/MIL_Experiment/imaging_results\n",
    "\n",
    "!mkdir /data\n",
    "!mkdir /data/MIL_Experiment\n",
    "!mkdir /data/MIL_Experiment/dataset\n",
    "\n",
    "print('Folder Tree Creation completed!')\n",
    "\n",
    "# get the latest code from Github MIL-SI official page\n",
    "!git clone https://$GITHUB_AUTH@github.com/sagizty/MIL-SI.git /home/MIL_Experiment/code\n",
    "print('code transfer from github completed!')\n",
    "\n",
    "# copy runs if u want to compare\n",
    "# !cp -r /content/drive/MyDrive/MIL_Experiment/runs/* /home/MIL_Experiment/runs\n",
    "# print('tensorboard log transfer completed!')\n",
    "\n",
    "# copy saved_models if u want to compare\n",
    "# !cp -r /content/drive/MyDrive/MIL_Experiment/saved_models/* /home/MIL_Experiment/saved_models\n",
    "# print('saved_models transfer completed!')\n",
    "\n",
    "# get the MIL and CLS dataset from github\n",
    "# by its zip\n",
    "!cp /home/MIL_Experiment/code/sample_datasets/warwick_MIL.zip /data/MIL_Experiment/dataset/\n",
    "!cp /home/MIL_Experiment/code/sample_datasets/warwick_CLS.zip /data/MIL_Experiment/dataset/\n",
    "# unzip\n",
    "!unzip -q /data/MIL_Experiment/dataset/warwick_MIL.zip -d /data/MIL_Experiment/dataset/\n",
    "!unzip -q /data/MIL_Experiment/dataset/warwick_CLS.zip -d /data/MIL_Experiment/dataset/\n",
    "# alter the path\n",
    "!rm -rf /data/MIL_Experiment/dataset/warwick_MIL.zip\n",
    "!rm -rf /data/MIL_Experiment/dataset/warwick_CLS.zip\n",
    "print('data transfer completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLxxHGq_wwwL"
   },
   "source": [
    "## Arrange the working enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1Yb2b6TGF4r",
    "outputId": "51fed8f8-8491-455e-fbeb-9b0bdb062bdb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651152814486,
     "user_tz": -480,
     "elapsed": 12787,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/MIL_Experiment/code\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
      "\u001B[K     |████████████████████████████████| 125 kB 5.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.5\n",
      "Collecting timm\n",
      "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
      "\u001B[K     |████████████████████████████████| 431 kB 5.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.5.4\n",
      "Collecting notifyemail\n",
      "  Downloading notifyemail-1.0.2-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: notifyemail\n",
      "Successfully installed notifyemail-1.0.2\n",
      "Collecting ttach\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: ttach\n",
      "Successfully installed ttach-0.0.3\n"
     ]
    }
   ],
   "source": [
    "# change working dir\n",
    "import os\n",
    "os.chdir(\"/home/MIL_Experiment/code\")\n",
    "!pwd\n",
    "\n",
    "# get packages\n",
    "!pip install tensorboardX\n",
    "!pip install timm\n",
    "!pip install notifyemail\n",
    "!pip install ttach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "87Owjg_pN2yD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651152814486,
     "user_tz": -480,
     "elapsed": 14,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "f59e7190-0ebf-4dda-c686-03b9029f56eb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python 3.7.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GpEVUWwqK79D",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651152815433,
     "user_tz": -480,
     "elapsed": 951,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "5b3c2f34-29ec-4059-a479-34a47bed37a6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Package                       Version\n",
      "----------------------------- ---------------------\n",
      "absl-py                       1.0.0\n",
      "alabaster                     0.7.12\n",
      "albumentations                0.1.12\n",
      "altair                        4.2.0\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arviz                         0.12.0\n",
      "astor                         0.8.1\n",
      "astropy                       4.3.1\n",
      "astunparse                    1.6.3\n",
      "atari-py                      0.2.9\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.4.0\n",
      "audioread                     2.1.9\n",
      "autograd                      1.4\n",
      "Babel                         2.9.1\n",
      "backcall                      0.2.0\n",
      "beautifulsoup4                4.6.3\n",
      "bleach                        5.0.0\n",
      "blis                          0.4.1\n",
      "bokeh                         2.3.3\n",
      "Bottleneck                    1.3.4\n",
      "branca                        0.5.0\n",
      "bs4                           0.0.1\n",
      "CacheControl                  0.12.10\n",
      "cached-property               1.5.2\n",
      "cachetools                    4.2.4\n",
      "catalogue                     1.0.0\n",
      "certifi                       2021.10.8\n",
      "cffi                          1.15.0\n",
      "cftime                        1.6.0\n",
      "chardet                       3.0.4\n",
      "charset-normalizer            2.0.12\n",
      "click                         7.1.2\n",
      "cloudpickle                   1.3.0\n",
      "cmake                         3.12.0\n",
      "cmdstanpy                     0.9.5\n",
      "colorcet                      3.0.0\n",
      "colorlover                    0.3.0\n",
      "community                     1.0.0b1\n",
      "contextlib2                   0.5.5\n",
      "convertdate                   2.4.0\n",
      "coverage                      3.7.1\n",
      "coveralls                     0.5\n",
      "crcmod                        1.7\n",
      "cufflinks                     0.17.3\n",
      "cupy-cuda111                  9.4.0\n",
      "cvxopt                        1.2.7\n",
      "cvxpy                         1.0.31\n",
      "cycler                        0.11.0\n",
      "cymem                         2.0.6\n",
      "Cython                        0.29.28\n",
      "daft                          0.0.4\n",
      "dask                          2.12.0\n",
      "datascience                   0.10.6\n",
      "debugpy                       1.0.0\n",
      "decorator                     4.4.2\n",
      "defusedxml                    0.7.1\n",
      "descartes                     1.1.0\n",
      "dill                          0.3.4\n",
      "distributed                   1.25.3\n",
      "dlib                          19.18.0\n",
      "dm-tree                       0.1.7\n",
      "docopt                        0.6.2\n",
      "docutils                      0.17.1\n",
      "dopamine-rl                   1.0.5\n",
      "earthengine-api               0.1.306\n",
      "easydict                      1.9\n",
      "ecos                          2.0.10\n",
      "editdistance                  0.5.3\n",
      "en-core-web-sm                2.2.5\n",
      "entrypoints                   0.4\n",
      "ephem                         4.1.3\n",
      "et-xmlfile                    1.1.0\n",
      "fa2                           0.3.5\n",
      "fastai                        1.0.61\n",
      "fastdtw                       0.3.4\n",
      "fastjsonschema                2.15.3\n",
      "fastprogress                  1.0.2\n",
      "fastrlock                     0.8\n",
      "fbprophet                     0.7.1\n",
      "feather-format                0.4.1\n",
      "filelock                      3.6.0\n",
      "firebase-admin                4.4.0\n",
      "fix-yahoo-finance             0.0.22\n",
      "Flask                         1.1.4\n",
      "flatbuffers                   2.0\n",
      "folium                        0.8.3\n",
      "future                        0.16.0\n",
      "gast                          0.5.3\n",
      "GDAL                          2.2.2\n",
      "gdown                         4.4.0\n",
      "gensim                        3.6.0\n",
      "geographiclib                 1.52\n",
      "geopy                         1.17.0\n",
      "gin-config                    0.5.0\n",
      "glob2                         0.7\n",
      "google                        2.0.3\n",
      "google-api-core               1.31.5\n",
      "google-api-python-client      1.12.11\n",
      "google-auth                   1.35.0\n",
      "google-auth-httplib2          0.0.4\n",
      "google-auth-oauthlib          0.4.6\n",
      "google-cloud-bigquery         1.21.0\n",
      "google-cloud-bigquery-storage 1.1.1\n",
      "google-cloud-core             1.0.3\n",
      "google-cloud-datastore        1.8.0\n",
      "google-cloud-firestore        1.7.0\n",
      "google-cloud-language         1.2.0\n",
      "google-cloud-storage          1.18.1\n",
      "google-cloud-translate        1.5.0\n",
      "google-colab                  1.0.0\n",
      "google-pasta                  0.2.0\n",
      "google-resumable-media        0.4.1\n",
      "googleapis-common-protos      1.56.0\n",
      "googledrivedownloader         0.4\n",
      "graphviz                      0.10.1\n",
      "greenlet                      1.1.2\n",
      "grpcio                        1.44.0\n",
      "gspread                       3.4.2\n",
      "gspread-dataframe             3.0.8\n",
      "gym                           0.17.3\n",
      "h5py                          3.1.0\n",
      "HeapDict                      1.0.1\n",
      "hijri-converter               2.2.3\n",
      "holidays                      0.10.5.2\n",
      "holoviews                     1.14.8\n",
      "html5lib                      1.0.1\n",
      "httpimport                    0.5.18\n",
      "httplib2                      0.17.4\n",
      "httplib2shim                  0.0.3\n",
      "humanize                      0.5.1\n",
      "hyperopt                      0.1.2\n",
      "ideep4py                      2.0.0.post3\n",
      "idna                          2.10\n",
      "imageio                       2.4.1\n",
      "imagesize                     1.3.0\n",
      "imbalanced-learn              0.8.1\n",
      "imblearn                      0.0\n",
      "imgaug                        0.2.9\n",
      "importlib-metadata            4.11.3\n",
      "importlib-resources           5.7.1\n",
      "imutils                       0.5.4\n",
      "inflect                       2.1.0\n",
      "iniconfig                     1.1.1\n",
      "intel-openmp                  2022.0.2\n",
      "intervaltree                  2.1.0\n",
      "ipykernel                     4.10.1\n",
      "ipython                       5.5.0\n",
      "ipython-genutils              0.2.0\n",
      "ipython-sql                   0.3.9\n",
      "ipywidgets                    7.7.0\n",
      "itsdangerous                  1.1.0\n",
      "jax                           0.3.4\n",
      "jaxlib                        0.3.2+cuda11.cudnn805\n",
      "jedi                          0.18.1\n",
      "jieba                         0.42.1\n",
      "Jinja2                        2.11.3\n",
      "joblib                        1.1.0\n",
      "jpeg4py                       0.1.4\n",
      "jsonschema                    4.3.3\n",
      "jupyter                       1.0.0\n",
      "jupyter-client                5.3.5\n",
      "jupyter-console               5.2.0\n",
      "jupyter-core                  4.10.0\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab-widgets            1.1.0\n",
      "kaggle                        1.5.12\n",
      "kapre                         0.3.7\n",
      "keras                         2.8.0\n",
      "Keras-Preprocessing           1.1.2\n",
      "keras-vis                     0.4.1\n",
      "kiwisolver                    1.4.2\n",
      "korean-lunar-calendar         0.2.1\n",
      "libclang                      13.0.0\n",
      "librosa                       0.8.1\n",
      "lightgbm                      2.2.3\n",
      "llvmlite                      0.34.0\n",
      "lmdb                          0.99\n",
      "LunarCalendar                 0.0.9\n",
      "lxml                          4.2.6\n",
      "Markdown                      3.3.6\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.2.2\n",
      "matplotlib-inline             0.1.3\n",
      "matplotlib-venn               0.11.7\n",
      "missingno                     0.5.1\n",
      "mistune                       0.8.4\n",
      "mizani                        0.6.0\n",
      "mkl                           2019.0\n",
      "mlxtend                       0.14.0\n",
      "more-itertools                8.12.0\n",
      "moviepy                       0.2.3.5\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.3\n",
      "multiprocess                  0.70.12.2\n",
      "multitasking                  0.0.10\n",
      "murmurhash                    1.0.6\n",
      "music21                       5.5.0\n",
      "natsort                       5.5.0\n",
      "nbclient                      0.6.0\n",
      "nbconvert                     5.6.1\n",
      "nbformat                      5.3.0\n",
      "nest-asyncio                  1.5.5\n",
      "netCDF4                       1.5.8\n",
      "networkx                      2.6.3\n",
      "nibabel                       3.0.2\n",
      "nltk                          3.2.5\n",
      "notebook                      5.3.1\n",
      "notifyemail                   1.0.2\n",
      "numba                         0.51.2\n",
      "numexpr                       2.8.1\n",
      "numpy                         1.21.6\n",
      "nvidia-ml-py3                 7.352.0\n",
      "oauth2client                  4.1.3\n",
      "oauthlib                      3.2.0\n",
      "okgrade                       0.4.3\n",
      "opencv-contrib-python         4.1.2.30\n",
      "opencv-python                 4.1.2.30\n",
      "openpyxl                      3.0.9\n",
      "opt-einsum                    3.3.0\n",
      "osqp                          0.6.2.post0\n",
      "packaging                     21.3\n",
      "palettable                    3.3.0\n",
      "pandas                        1.3.5\n",
      "pandas-datareader             0.9.0\n",
      "pandas-gbq                    0.13.3\n",
      "pandas-profiling              1.4.1\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.12.1\n",
      "param                         1.12.1\n",
      "parso                         0.8.3\n",
      "pathlib                       1.0.1\n",
      "patsy                         0.5.2\n",
      "pep517                        0.12.0\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        7.1.2\n",
      "pip                           21.1.3\n",
      "pip-tools                     6.2.0\n",
      "plac                          1.1.3\n",
      "plotly                        5.5.0\n",
      "plotnine                      0.6.0\n",
      "pluggy                        0.7.1\n",
      "pooch                         1.6.0\n",
      "portpicker                    1.3.9\n",
      "prefetch-generator            1.0.1\n",
      "preshed                       3.0.6\n",
      "prettytable                   3.2.0\n",
      "progressbar2                  3.38.0\n",
      "prometheus-client             0.14.1\n",
      "promise                       2.3\n",
      "prompt-toolkit                1.0.18\n",
      "protobuf                      3.17.3\n",
      "psutil                        5.4.8\n",
      "psycopg2                      2.7.6.1\n",
      "ptyprocess                    0.7.0\n",
      "py                            1.11.0\n",
      "pyarrow                       6.0.1\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycocotools                   2.0.4\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.8\n",
      "pydata-google-auth            1.4.0\n",
      "pydot                         1.3.0\n",
      "pydot-ng                      2.0.0\n",
      "pydotplus                     2.0.2\n",
      "PyDrive                       1.3.1\n",
      "pyemd                         0.5.1\n",
      "pyerfa                        2.0.0.1\n",
      "pyglet                        1.5.0\n",
      "Pygments                      2.6.1\n",
      "pygobject                     3.26.1\n",
      "pymc3                         3.11.4\n",
      "PyMeeus                       0.5.11\n",
      "pymongo                       4.1.1\n",
      "pymystem3                     0.2.0\n",
      "PyOpenGL                      3.1.6\n",
      "pyparsing                     3.0.8\n",
      "pyrsistent                    0.18.1\n",
      "pysndfile                     1.3.8\n",
      "PySocks                       1.7.1\n",
      "pystan                        2.19.1.1\n",
      "pytest                        3.6.4\n",
      "python-apt                    0.0.0\n",
      "python-chess                  0.23.11\n",
      "python-dateutil               2.8.2\n",
      "python-louvain                0.16\n",
      "python-slugify                6.1.1\n",
      "python-utils                  3.1.0\n",
      "pytz                          2022.1\n",
      "pyviz-comms                   2.2.0\n",
      "PyWavelets                    1.3.0\n",
      "PyYAML                        3.13\n",
      "pyzmq                         22.3.0\n",
      "qdldl                         0.1.5.post2\n",
      "qtconsole                     5.3.0\n",
      "QtPy                          2.0.1\n",
      "regex                         2019.12.20\n",
      "requests                      2.23.0\n",
      "requests-oauthlib             1.3.1\n",
      "resampy                       0.2.2\n",
      "rpy2                          3.4.5\n",
      "rsa                           4.8\n",
      "scikit-image                  0.18.3\n",
      "scikit-learn                  1.0.2\n",
      "scipy                         1.4.1\n",
      "screen-resolution-extra       0.0.0\n",
      "scs                           3.2.0\n",
      "seaborn                       0.11.2\n",
      "semver                        2.13.0\n",
      "Send2Trash                    1.8.0\n",
      "setuptools                    57.4.0\n",
      "setuptools-git                1.2\n",
      "Shapely                       1.8.1.post1\n",
      "simplegeneric                 0.8.1\n",
      "six                           1.15.0\n",
      "sklearn                       0.0\n",
      "sklearn-pandas                1.8.0\n",
      "smart-open                    5.2.1\n",
      "snowballstemmer               2.2.0\n",
      "sortedcontainers              2.4.0\n",
      "SoundFile                     0.10.3.post1\n",
      "soupsieve                     2.3.2.post1\n",
      "spacy                         2.2.4\n",
      "Sphinx                        1.8.6\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "sphinxcontrib-websupport      1.2.4\n",
      "SQLAlchemy                    1.4.35\n",
      "sqlparse                      0.4.2\n",
      "srsly                         1.0.5\n",
      "statsmodels                   0.10.2\n",
      "sympy                         1.7.1\n",
      "tables                        3.7.0\n",
      "tabulate                      0.8.9\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.0.1\n",
      "tensorboard                   2.8.0\n",
      "tensorboard-data-server       0.6.1\n",
      "tensorboard-plugin-wit        1.8.1\n",
      "tensorboardX                  2.5\n",
      "tensorflow                    2.8.0\n",
      "tensorflow-datasets           4.0.1\n",
      "tensorflow-estimator          2.8.0\n",
      "tensorflow-gcs-config         2.8.0\n",
      "tensorflow-hub                0.12.0\n",
      "tensorflow-io-gcs-filesystem  0.24.0\n",
      "tensorflow-metadata           1.7.0\n",
      "tensorflow-probability        0.16.0\n",
      "termcolor                     1.1.0\n",
      "terminado                     0.13.3\n",
      "testpath                      0.6.0\n",
      "text-unidecode                1.3\n",
      "textblob                      0.15.3\n",
      "Theano-PyMC                   1.1.2\n",
      "thinc                         7.4.0\n",
      "threadpoolctl                 3.1.0\n",
      "tifffile                      2021.11.2\n",
      "timm                          0.5.4\n",
      "tinycss2                      1.1.1\n",
      "tomli                         2.0.1\n",
      "toolz                         0.11.2\n",
      "torch                         1.11.0+cu113\n",
      "torchaudio                    0.11.0+cu113\n",
      "torchsummary                  1.5.1\n",
      "torchtext                     0.12.0\n",
      "torchvision                   0.12.0+cu113\n",
      "tornado                       5.1.1\n",
      "tqdm                          4.64.0\n",
      "traitlets                     5.1.1\n",
      "ttach                         0.0.3\n",
      "tweepy                        3.10.0\n",
      "typeguard                     2.7.1\n",
      "typing-extensions             4.2.0\n",
      "tzlocal                       1.5.1\n",
      "uritemplate                   3.0.1\n",
      "urllib3                       1.24.3\n",
      "vega-datasets                 0.9.0\n",
      "wasabi                        0.9.1\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "Werkzeug                      1.0.1\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.6.0\n",
      "wordcloud                     1.5.0\n",
      "wrapt                         1.14.0\n",
      "xarray                        0.18.2\n",
      "xgboost                       0.90\n",
      "xkit                          0.0.0\n",
      "xlrd                          1.1.0\n",
      "xlwt                          1.3.0\n",
      "yellowbrick                   1.4\n",
      "zict                          2.1.0\n",
      "zipp                          3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h31KAx1ZZEl9"
   },
   "source": [
    "## Start Training\n",
    "* by command line\n",
    "* use argparse to set down hyper-parameter\n",
    "\n",
    "* 5-fold experiment is used here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruFuG07xOftS"
   },
   "source": [
    "# MIL Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMeCgHQ7OpFQ"
   },
   "source": [
    "* Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnCOfr2pXjs4",
    "outputId": "bdb7a852-780f-4b20-cb23-4e3cd2b83eb8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153453248,
     "user_tz": -480,
     "elapsed": 637818,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU: 0\n",
      "*********************************setting*************************************\n",
      "Namespace(CLS_MIL_head_weight=1.0, CLS_MIL_off=False, MIL_head_weight=1.0, Pre_Trained_model_path=None, backbone_PT_off=False, batch_size=4, check_minibatch=5, data_augmentation_mode=2, dataroot='/data/MIL_Experiment/dataset/warwick_MIL', draw_root='/home/MIL_Experiment/runs', edge_size=384, enable_attention_check=False, enable_notify=False, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=0, intake_epochs=0, lr=1e-05, lrf=0.05, model_idx='ViT_384_401_PT_lf05_b4_p32_warwick_MIL', model_path='/home/MIL_Experiment/saved_models', num_epochs=50, num_workers=2, opt_name='Adam', paint=True, patch_size=32, shuffle_MIL_off=False)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 24, 24]         590,592\n",
      "        PatchEmbed-2             [-1, 576, 768]               0\n",
      "           Dropout-3             [-1, 577, 768]               0\n",
      "         LayerNorm-4             [-1, 577, 768]           1,536\n",
      "            Linear-5            [-1, 577, 2304]       1,771,776\n",
      "           Dropout-6         [-1, 12, 577, 577]               0\n",
      "            Linear-7             [-1, 577, 768]         590,592\n",
      "           Dropout-8             [-1, 577, 768]               0\n",
      "         Attention-9             [-1, 577, 768]               0\n",
      "         Identity-10             [-1, 577, 768]               0\n",
      "        LayerNorm-11             [-1, 577, 768]           1,536\n",
      "           Linear-12            [-1, 577, 3072]       2,362,368\n",
      "             GELU-13            [-1, 577, 3072]               0\n",
      "          Dropout-14            [-1, 577, 3072]               0\n",
      "           Linear-15             [-1, 577, 768]       2,360,064\n",
      "          Dropout-16             [-1, 577, 768]               0\n",
      "              FFN-17             [-1, 577, 768]               0\n",
      "         Identity-18             [-1, 577, 768]               0\n",
      "    Encoder_Block-19             [-1, 577, 768]               0\n",
      "        LayerNorm-20             [-1, 577, 768]           1,536\n",
      "           Linear-21            [-1, 577, 2304]       1,771,776\n",
      "          Dropout-22         [-1, 12, 577, 577]               0\n",
      "           Linear-23             [-1, 577, 768]         590,592\n",
      "          Dropout-24             [-1, 577, 768]               0\n",
      "        Attention-25             [-1, 577, 768]               0\n",
      "         Identity-26             [-1, 577, 768]               0\n",
      "        LayerNorm-27             [-1, 577, 768]           1,536\n",
      "           Linear-28            [-1, 577, 3072]       2,362,368\n",
      "             GELU-29            [-1, 577, 3072]               0\n",
      "          Dropout-30            [-1, 577, 3072]               0\n",
      "           Linear-31             [-1, 577, 768]       2,360,064\n",
      "          Dropout-32             [-1, 577, 768]               0\n",
      "              FFN-33             [-1, 577, 768]               0\n",
      "         Identity-34             [-1, 577, 768]               0\n",
      "    Encoder_Block-35             [-1, 577, 768]               0\n",
      "        LayerNorm-36             [-1, 577, 768]           1,536\n",
      "           Linear-37            [-1, 577, 2304]       1,771,776\n",
      "          Dropout-38         [-1, 12, 577, 577]               0\n",
      "           Linear-39             [-1, 577, 768]         590,592\n",
      "          Dropout-40             [-1, 577, 768]               0\n",
      "        Attention-41             [-1, 577, 768]               0\n",
      "         Identity-42             [-1, 577, 768]               0\n",
      "        LayerNorm-43             [-1, 577, 768]           1,536\n",
      "           Linear-44            [-1, 577, 3072]       2,362,368\n",
      "             GELU-45            [-1, 577, 3072]               0\n",
      "          Dropout-46            [-1, 577, 3072]               0\n",
      "           Linear-47             [-1, 577, 768]       2,360,064\n",
      "          Dropout-48             [-1, 577, 768]               0\n",
      "              FFN-49             [-1, 577, 768]               0\n",
      "         Identity-50             [-1, 577, 768]               0\n",
      "    Encoder_Block-51             [-1, 577, 768]               0\n",
      "        LayerNorm-52             [-1, 577, 768]           1,536\n",
      "           Linear-53            [-1, 577, 2304]       1,771,776\n",
      "          Dropout-54         [-1, 12, 577, 577]               0\n",
      "           Linear-55             [-1, 577, 768]         590,592\n",
      "          Dropout-56             [-1, 577, 768]               0\n",
      "        Attention-57             [-1, 577, 768]               0\n",
      "         Identity-58             [-1, 577, 768]               0\n",
      "        LayerNorm-59             [-1, 577, 768]           1,536\n",
      "           Linear-60            [-1, 577, 3072]       2,362,368\n",
      "             GELU-61            [-1, 577, 3072]               0\n",
      "          Dropout-62            [-1, 577, 3072]               0\n",
      "           Linear-63             [-1, 577, 768]       2,360,064\n",
      "          Dropout-64             [-1, 577, 768]               0\n",
      "              FFN-65             [-1, 577, 768]               0\n",
      "         Identity-66             [-1, 577, 768]               0\n",
      "    Encoder_Block-67             [-1, 577, 768]               0\n",
      "        LayerNorm-68             [-1, 577, 768]           1,536\n",
      "           Linear-69            [-1, 577, 2304]       1,771,776\n",
      "          Dropout-70         [-1, 12, 577, 577]               0\n",
      "           Linear-71             [-1, 577, 768]         590,592\n",
      "          Dropout-72             [-1, 577, 768]               0\n",
      "        Attention-73             [-1, 577, 768]               0\n",
      "         Identity-74             [-1, 577, 768]               0\n",
      "        LayerNorm-75             [-1, 577, 768]           1,536\n",
      "           Linear-76            [-1, 577, 3072]       2,362,368\n",
      "             GELU-77            [-1, 577, 3072]               0\n",
      "          Dropout-78            [-1, 577, 3072]               0\n",
      "           Linear-79             [-1, 577, 768]       2,360,064\n",
      "          Dropout-80             [-1, 577, 768]               0\n",
      "              FFN-81             [-1, 577, 768]               0\n",
      "         Identity-82             [-1, 577, 768]               0\n",
      "    Encoder_Block-83             [-1, 577, 768]               0\n",
      "        LayerNorm-84             [-1, 577, 768]           1,536\n",
      "           Linear-85            [-1, 577, 2304]       1,771,776\n",
      "          Dropout-86         [-1, 12, 577, 577]               0\n",
      "           Linear-87             [-1, 577, 768]         590,592\n",
      "          Dropout-88             [-1, 577, 768]               0\n",
      "        Attention-89             [-1, 577, 768]               0\n",
      "         Identity-90             [-1, 577, 768]               0\n",
      "        LayerNorm-91             [-1, 577, 768]           1,536\n",
      "           Linear-92            [-1, 577, 3072]       2,362,368\n",
      "             GELU-93            [-1, 577, 3072]               0\n",
      "          Dropout-94            [-1, 577, 3072]               0\n",
      "           Linear-95             [-1, 577, 768]       2,360,064\n",
      "          Dropout-96             [-1, 577, 768]               0\n",
      "              FFN-97             [-1, 577, 768]               0\n",
      "         Identity-98             [-1, 577, 768]               0\n",
      "    Encoder_Block-99             [-1, 577, 768]               0\n",
      "       LayerNorm-100             [-1, 577, 768]           1,536\n",
      "          Linear-101            [-1, 577, 2304]       1,771,776\n",
      "         Dropout-102         [-1, 12, 577, 577]               0\n",
      "          Linear-103             [-1, 577, 768]         590,592\n",
      "         Dropout-104             [-1, 577, 768]               0\n",
      "       Attention-105             [-1, 577, 768]               0\n",
      "        Identity-106             [-1, 577, 768]               0\n",
      "       LayerNorm-107             [-1, 577, 768]           1,536\n",
      "          Linear-108            [-1, 577, 3072]       2,362,368\n",
      "            GELU-109            [-1, 577, 3072]               0\n",
      "         Dropout-110            [-1, 577, 3072]               0\n",
      "          Linear-111             [-1, 577, 768]       2,360,064\n",
      "         Dropout-112             [-1, 577, 768]               0\n",
      "             FFN-113             [-1, 577, 768]               0\n",
      "        Identity-114             [-1, 577, 768]               0\n",
      "   Encoder_Block-115             [-1, 577, 768]               0\n",
      "       LayerNorm-116             [-1, 577, 768]           1,536\n",
      "          Linear-117            [-1, 577, 2304]       1,771,776\n",
      "         Dropout-118         [-1, 12, 577, 577]               0\n",
      "          Linear-119             [-1, 577, 768]         590,592\n",
      "         Dropout-120             [-1, 577, 768]               0\n",
      "       Attention-121             [-1, 577, 768]               0\n",
      "        Identity-122             [-1, 577, 768]               0\n",
      "       LayerNorm-123             [-1, 577, 768]           1,536\n",
      "          Linear-124            [-1, 577, 3072]       2,362,368\n",
      "            GELU-125            [-1, 577, 3072]               0\n",
      "         Dropout-126            [-1, 577, 3072]               0\n",
      "          Linear-127             [-1, 577, 768]       2,360,064\n",
      "         Dropout-128             [-1, 577, 768]               0\n",
      "             FFN-129             [-1, 577, 768]               0\n",
      "        Identity-130             [-1, 577, 768]               0\n",
      "   Encoder_Block-131             [-1, 577, 768]               0\n",
      "       LayerNorm-132             [-1, 577, 768]           1,536\n",
      "          Linear-133            [-1, 577, 2304]       1,771,776\n",
      "         Dropout-134         [-1, 12, 577, 577]               0\n",
      "          Linear-135             [-1, 577, 768]         590,592\n",
      "         Dropout-136             [-1, 577, 768]               0\n",
      "       Attention-137             [-1, 577, 768]               0\n",
      "        Identity-138             [-1, 577, 768]               0\n",
      "       LayerNorm-139             [-1, 577, 768]           1,536\n",
      "          Linear-140            [-1, 577, 3072]       2,362,368\n",
      "            GELU-141            [-1, 577, 3072]               0\n",
      "         Dropout-142            [-1, 577, 3072]               0\n",
      "          Linear-143             [-1, 577, 768]       2,360,064\n",
      "         Dropout-144             [-1, 577, 768]               0\n",
      "             FFN-145             [-1, 577, 768]               0\n",
      "        Identity-146             [-1, 577, 768]               0\n",
      "   Encoder_Block-147             [-1, 577, 768]               0\n",
      "       LayerNorm-148             [-1, 577, 768]           1,536\n",
      "          Linear-149            [-1, 577, 2304]       1,771,776\n",
      "         Dropout-150         [-1, 12, 577, 577]               0\n",
      "          Linear-151             [-1, 577, 768]         590,592\n",
      "         Dropout-152             [-1, 577, 768]               0\n",
      "       Attention-153             [-1, 577, 768]               0\n",
      "        Identity-154             [-1, 577, 768]               0\n",
      "       LayerNorm-155             [-1, 577, 768]           1,536\n",
      "          Linear-156            [-1, 577, 3072]       2,362,368\n",
      "            GELU-157            [-1, 577, 3072]               0\n",
      "         Dropout-158            [-1, 577, 3072]               0\n",
      "          Linear-159             [-1, 577, 768]       2,360,064\n",
      "         Dropout-160             [-1, 577, 768]               0\n",
      "             FFN-161             [-1, 577, 768]               0\n",
      "        Identity-162             [-1, 577, 768]               0\n",
      "   Encoder_Block-163             [-1, 577, 768]               0\n",
      "       LayerNorm-164             [-1, 577, 768]           1,536\n",
      "          Linear-165            [-1, 577, 2304]       1,771,776\n",
      "         Dropout-166         [-1, 12, 577, 577]               0\n",
      "          Linear-167             [-1, 577, 768]         590,592\n",
      "         Dropout-168             [-1, 577, 768]               0\n",
      "       Attention-169             [-1, 577, 768]               0\n",
      "        Identity-170             [-1, 577, 768]               0\n",
      "       LayerNorm-171             [-1, 577, 768]           1,536\n",
      "          Linear-172            [-1, 577, 3072]       2,362,368\n",
      "            GELU-173            [-1, 577, 3072]               0\n",
      "         Dropout-174            [-1, 577, 3072]               0\n",
      "          Linear-175             [-1, 577, 768]       2,360,064\n",
      "         Dropout-176             [-1, 577, 768]               0\n",
      "             FFN-177             [-1, 577, 768]               0\n",
      "        Identity-178             [-1, 577, 768]               0\n",
      "   Encoder_Block-179             [-1, 577, 768]               0\n",
      "       LayerNorm-180             [-1, 577, 768]           1,536\n",
      "          Linear-181            [-1, 577, 2304]       1,771,776\n",
      "         Dropout-182         [-1, 12, 577, 577]               0\n",
      "          Linear-183             [-1, 577, 768]         590,592\n",
      "         Dropout-184             [-1, 577, 768]               0\n",
      "       Attention-185             [-1, 577, 768]               0\n",
      "        Identity-186             [-1, 577, 768]               0\n",
      "       LayerNorm-187             [-1, 577, 768]           1,536\n",
      "          Linear-188            [-1, 577, 3072]       2,362,368\n",
      "            GELU-189            [-1, 577, 3072]               0\n",
      "         Dropout-190            [-1, 577, 3072]               0\n",
      "          Linear-191             [-1, 577, 768]       2,360,064\n",
      "         Dropout-192             [-1, 577, 768]               0\n",
      "             FFN-193             [-1, 577, 768]               0\n",
      "        Identity-194             [-1, 577, 768]               0\n",
      "   Encoder_Block-195             [-1, 577, 768]               0\n",
      "       LayerNorm-196             [-1, 577, 768]           1,536\n",
      "VisionTransformer-197             [-1, 577, 768]               0\n",
      "          Linear-198                  [-1, 288]     127,402,272\n",
      "            GELU-199                  [-1, 288]               0\n",
      "          Linear-200                  [-1, 288]          83,232\n",
      "            GELU-201                  [-1, 288]               0\n",
      "          Linear-202                    [-1, 3]             867\n",
      "         Dropout-203                    [-1, 3]               0\n",
      "represtation_MLP-204                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 213,132,963\n",
      "Trainable params: 213,132,963\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 1437.50\n",
      "Params size (MB): 813.04\n",
      "Estimated Total Size (MB): 2252.22\n",
      "----------------------------------------------------------------\n",
      "model : ViT_384_401_PT_lf05_b4_p32_warwick_MIL\n",
      "Epoch 1/50\n",
      "----------\n",
      "Epoch: 1     train index of 5 minibatch: 1      time used: 3.562105417251587\n",
      "minibatch AVG loss: 88.83289337158203\n",
      "Epoch: 1     train index of 5 minibatch: 2      time used: 3.0745866298675537\n",
      "minibatch AVG loss: 66.16417922973633\n",
      "Epoch: 1     train index of 5 minibatch: 3      time used: 3.0708141326904297\n",
      "minibatch AVG loss: 62.46100616455078\n",
      "\n",
      "Epoch: 1  train \n",
      "Loss: 69.8905  Acc: 68.1159\n",
      "benign precision: 65.3846  recall: 56.6667\n",
      "benign sensitivity: 56.6667  specificity: 76.9231\n",
      "benign FPR: 23.0769  NPV: 69.7674\n",
      "benign TP: 17.0\n",
      "benign TN: 30.0\n",
      "benign FP: 9.0\n",
      "benign FN: 13.0\n",
      "malignant precision: 69.7674  recall: 76.9231\n",
      "malignant sensitivity: 76.9231  specificity: 56.6667\n",
      "malignant FPR: 43.3333  NPV: 65.3846\n",
      "malignant TP: 30.0\n",
      "malignant TN: 17.0\n",
      "malignant FP: 13.0\n",
      "malignant FN: 9.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1  val \n",
      "Loss: 44.9915  Acc: 87.5000\n",
      "benign precision: 100.0000  recall: 71.4286\n",
      "benign sensitivity: 71.4286  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 81.8182\n",
      "benign TP: 5.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 2.0\n",
      "malignant precision: 81.8182  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 71.4286\n",
      "malignant FPR: 28.5714  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 5.0\n",
      "malignant FP: 2.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/50\n",
      "----------\n",
      "Epoch: 2     train index of 5 minibatch: 1      time used: 3.5009310245513916\n",
      "minibatch AVG loss: 48.15364074707031\n",
      "Epoch: 2     train index of 5 minibatch: 2      time used: 3.0702755451202393\n",
      "minibatch AVG loss: 52.09933776855469\n",
      "Epoch: 2     train index of 5 minibatch: 3      time used: 3.0682950019836426\n",
      "minibatch AVG loss: 50.61640319824219\n",
      "\n",
      "Epoch: 2  train \n",
      "Loss: 51.4873  Acc: 85.5072\n",
      "benign precision: 76.3158  recall: 96.6667\n",
      "benign sensitivity: 96.6667  specificity: 76.9231\n",
      "benign FPR: 23.0769  NPV: 96.7742\n",
      "benign TP: 29.0\n",
      "benign TN: 30.0\n",
      "benign FP: 9.0\n",
      "benign FN: 1.0\n",
      "malignant precision: 96.7742  recall: 76.9231\n",
      "malignant sensitivity: 76.9231  specificity: 96.6667\n",
      "malignant FPR: 3.3333  NPV: 76.3158\n",
      "malignant TP: 30.0\n",
      "malignant TN: 29.0\n",
      "malignant FP: 1.0\n",
      "malignant FN: 9.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2  val \n",
      "Loss: 47.8771  Acc: 87.5000\n",
      "benign precision: 100.0000  recall: 71.4286\n",
      "benign sensitivity: 71.4286  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 81.8182\n",
      "benign TP: 5.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 2.0\n",
      "malignant precision: 81.8182  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 71.4286\n",
      "malignant FPR: 28.5714  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 5.0\n",
      "malignant FP: 2.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/50\n",
      "----------\n",
      "Epoch: 3     train index of 5 minibatch: 1      time used: 3.49786114692688\n",
      "minibatch AVG loss: 47.799983215332034\n",
      "Epoch: 3     train index of 5 minibatch: 2      time used: 3.075368642807007\n",
      "minibatch AVG loss: 50.22217330932617\n",
      "Epoch: 3     train index of 5 minibatch: 3      time used: 3.0739266872406006\n",
      "minibatch AVG loss: 42.76724052429199\n",
      "\n",
      "Epoch: 3  train \n",
      "Loss: 46.9847  Acc: 86.9565\n",
      "benign precision: 86.2069  recall: 83.3333\n",
      "benign sensitivity: 83.3333  specificity: 89.7436\n",
      "benign FPR: 10.2564  NPV: 87.5000\n",
      "benign TP: 25.0\n",
      "benign TN: 35.0\n",
      "benign FP: 4.0\n",
      "benign FN: 5.0\n",
      "malignant precision: 87.5000  recall: 89.7436\n",
      "malignant sensitivity: 89.7436  specificity: 83.3333\n",
      "malignant FPR: 16.6667  NPV: 86.2069\n",
      "malignant TP: 35.0\n",
      "malignant TN: 25.0\n",
      "malignant FP: 5.0\n",
      "malignant FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3  val \n",
      "Loss: 38.7783  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4/50\n",
      "----------\n",
      "Epoch: 4     train index of 5 minibatch: 1      time used: 3.5358476638793945\n",
      "minibatch AVG loss: 41.507249450683595\n",
      "Epoch: 4     train index of 5 minibatch: 2      time used: 3.0715465545654297\n",
      "minibatch AVG loss: 35.94304504394531\n",
      "Epoch: 4     train index of 5 minibatch: 3      time used: 3.0711684226989746\n",
      "minibatch AVG loss: 30.48740425109863\n",
      "\n",
      "Epoch: 4  train \n",
      "Loss: 37.5592  Acc: 98.5507\n",
      "benign precision: 100.0000  recall: 96.6667\n",
      "benign sensitivity: 96.6667  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 97.5000\n",
      "benign TP: 29.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 1.0\n",
      "malignant precision: 97.5000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 96.6667\n",
      "malignant FPR: 3.3333  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 29.0\n",
      "malignant FP: 1.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4  val \n",
      "Loss: 29.4039  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5/50\n",
      "----------\n",
      "Epoch: 5     train index of 5 minibatch: 1      time used: 3.536956310272217\n",
      "minibatch AVG loss: 33.03800659179687\n",
      "Epoch: 5     train index of 5 minibatch: 2      time used: 3.0746285915374756\n",
      "minibatch AVG loss: 24.935060882568358\n",
      "Epoch: 5     train index of 5 minibatch: 3      time used: 3.0725409984588623\n",
      "minibatch AVG loss: 20.428559875488283\n",
      "\n",
      "Epoch: 5  train \n",
      "Loss: 26.9095  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5  val \n",
      "Loss: 39.9976  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6/50\n",
      "----------\n",
      "Epoch: 6     train index of 5 minibatch: 1      time used: 3.4980764389038086\n",
      "minibatch AVG loss: 19.332532501220705\n",
      "Epoch: 6     train index of 5 minibatch: 2      time used: 3.0709564685821533\n",
      "minibatch AVG loss: 25.05061912536621\n",
      "Epoch: 6     train index of 5 minibatch: 3      time used: 3.0695669651031494\n",
      "minibatch AVG loss: 18.255734252929688\n",
      "\n",
      "Epoch: 6  train \n",
      "Loss: 21.1345  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6  val \n",
      "Loss: 40.4987  Acc: 93.7500\n",
      "benign precision: 87.5000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 88.8889\n",
      "benign FPR: 11.1111  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 8.0\n",
      "benign FP: 1.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 88.8889\n",
      "malignant sensitivity: 88.8889  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 87.5000\n",
      "malignant TP: 8.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7/50\n",
      "----------\n",
      "Epoch: 7     train index of 5 minibatch: 1      time used: 3.5388100147247314\n",
      "minibatch AVG loss: 25.3633695602417\n",
      "Epoch: 7     train index of 5 minibatch: 2      time used: 3.070589780807495\n",
      "minibatch AVG loss: 19.41239528656006\n",
      "Epoch: 7     train index of 5 minibatch: 3      time used: 3.069291830062866\n",
      "minibatch AVG loss: 27.531940078735353\n",
      "\n",
      "Epoch: 7  train \n",
      "Loss: 23.7904  Acc: 98.5507\n",
      "benign precision: 96.7742  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 97.4359\n",
      "benign FPR: 2.5641  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 38.0\n",
      "benign FP: 1.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 97.4359\n",
      "malignant sensitivity: 97.4359  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 96.7742\n",
      "malignant TP: 38.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7  val \n",
      "Loss: 35.3345  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8/50\n",
      "----------\n",
      "Epoch: 8     train index of 5 minibatch: 1      time used: 3.452920436859131\n",
      "minibatch AVG loss: 24.827820014953613\n",
      "Epoch: 8     train index of 5 minibatch: 2      time used: 3.0693955421447754\n",
      "minibatch AVG loss: 20.07596626281738\n",
      "Epoch: 8     train index of 5 minibatch: 3      time used: 3.0706632137298584\n",
      "minibatch AVG loss: 23.483460235595704\n",
      "\n",
      "Epoch: 8  train \n",
      "Loss: 21.9133  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8  val \n",
      "Loss: 35.1265  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9/50\n",
      "----------\n",
      "Epoch: 9     train index of 5 minibatch: 1      time used: 3.500786066055298\n",
      "minibatch AVG loss: 27.465798950195314\n",
      "Epoch: 9     train index of 5 minibatch: 2      time used: 3.071533441543579\n",
      "minibatch AVG loss: 23.74696159362793\n",
      "Epoch: 9     train index of 5 minibatch: 3      time used: 3.072678804397583\n",
      "minibatch AVG loss: 18.494731521606447\n",
      "\n",
      "Epoch: 9  train \n",
      "Loss: 23.1917  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9  val \n",
      "Loss: 44.7737  Acc: 93.7500\n",
      "benign precision: 100.0000  recall: 85.7143\n",
      "benign sensitivity: 85.7143  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 90.0000\n",
      "benign TP: 6.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 1.0\n",
      "malignant precision: 90.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 85.7143\n",
      "malignant FPR: 14.2857  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 6.0\n",
      "malignant FP: 1.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10/50\n",
      "----------\n",
      "Epoch: 10     train index of 5 minibatch: 1      time used: 3.5298917293548584\n",
      "minibatch AVG loss: 24.63326301574707\n",
      "Epoch: 10     train index of 5 minibatch: 2      time used: 3.0721328258514404\n",
      "minibatch AVG loss: 20.20880012512207\n",
      "Epoch: 10     train index of 5 minibatch: 3      time used: 3.0770511627197266\n",
      "minibatch AVG loss: 17.05292205810547\n",
      "\n",
      "Epoch: 10  train \n",
      "Loss: 21.2994  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 10  val \n",
      "Loss: 32.0364  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 11/50\n",
      "----------\n",
      "Epoch: 11     train index of 5 minibatch: 1      time used: 3.482706069946289\n",
      "minibatch AVG loss: 15.121327781677246\n",
      "Epoch: 11     train index of 5 minibatch: 2      time used: 3.0692501068115234\n",
      "minibatch AVG loss: 23.889081954956055\n",
      "Epoch: 11     train index of 5 minibatch: 3      time used: 3.069566249847412\n",
      "minibatch AVG loss: 17.708119583129882\n",
      "\n",
      "Epoch: 11  train \n",
      "Loss: 18.3312  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 11  val \n",
      "Loss: 36.8207  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 12/50\n",
      "----------\n",
      "Epoch: 12     train index of 5 minibatch: 1      time used: 3.5060486793518066\n",
      "minibatch AVG loss: 26.84227123260498\n",
      "Epoch: 12     train index of 5 minibatch: 2      time used: 3.070604085922241\n",
      "minibatch AVG loss: 19.02059383392334\n",
      "Epoch: 12     train index of 5 minibatch: 3      time used: 3.0709996223449707\n",
      "minibatch AVG loss: 17.40033378601074\n",
      "\n",
      "Epoch: 12  train \n",
      "Loss: 20.4777  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 12  val \n",
      "Loss: 29.2492  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 13/50\n",
      "----------\n",
      "Epoch: 13     train index of 5 minibatch: 1      time used: 3.513179063796997\n",
      "minibatch AVG loss: 10.847041893005372\n",
      "Epoch: 13     train index of 5 minibatch: 2      time used: 3.0711746215820312\n",
      "minibatch AVG loss: 19.979857444763184\n",
      "Epoch: 13     train index of 5 minibatch: 3      time used: 3.06990385055542\n",
      "minibatch AVG loss: 32.17211723327637\n",
      "\n",
      "Epoch: 13  train \n",
      "Loss: 20.5819  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 13  val \n",
      "Loss: 22.4365  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 14/50\n",
      "----------\n",
      "Epoch: 14     train index of 5 minibatch: 1      time used: 3.473639726638794\n",
      "minibatch AVG loss: 16.467291259765624\n",
      "Epoch: 14     train index of 5 minibatch: 2      time used: 3.072730541229248\n",
      "minibatch AVG loss: 16.29376811981201\n",
      "Epoch: 14     train index of 5 minibatch: 3      time used: 3.072744369506836\n",
      "minibatch AVG loss: 20.331645202636718\n",
      "\n",
      "Epoch: 14  train \n",
      "Loss: 17.3148  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 14  val \n",
      "Loss: 28.9767  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 15/50\n",
      "----------\n",
      "Epoch: 15     train index of 5 minibatch: 1      time used: 3.480158567428589\n",
      "minibatch AVG loss: 16.09573459625244\n",
      "Epoch: 15     train index of 5 minibatch: 2      time used: 3.070155382156372\n",
      "minibatch AVG loss: 11.824222373962403\n",
      "Epoch: 15     train index of 5 minibatch: 3      time used: 3.068756103515625\n",
      "minibatch AVG loss: 16.74014072418213\n",
      "\n",
      "Epoch: 15  train \n",
      "Loss: 15.6456  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 15  val \n",
      "Loss: 24.6544  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 16/50\n",
      "----------\n",
      "Epoch: 16     train index of 5 minibatch: 1      time used: 3.490199089050293\n",
      "minibatch AVG loss: 16.46659297943115\n",
      "Epoch: 16     train index of 5 minibatch: 2      time used: 3.0738983154296875\n",
      "minibatch AVG loss: 15.050194454193115\n",
      "Epoch: 16     train index of 5 minibatch: 3      time used: 3.0722129344940186\n",
      "minibatch AVG loss: 13.341695785522461\n",
      "\n",
      "Epoch: 16  train \n",
      "Loss: 14.5554  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 16  val \n",
      "Loss: 23.1913  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 17/50\n",
      "----------\n",
      "Epoch: 17     train index of 5 minibatch: 1      time used: 3.4943206310272217\n",
      "minibatch AVG loss: 15.161309623718262\n",
      "Epoch: 17     train index of 5 minibatch: 2      time used: 3.070664882659912\n",
      "minibatch AVG loss: 12.412935829162597\n",
      "Epoch: 17     train index of 5 minibatch: 3      time used: 3.0714197158813477\n",
      "minibatch AVG loss: 15.685807037353516\n",
      "\n",
      "Epoch: 17  train \n",
      "Loss: 14.3604  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 17  val \n",
      "Loss: 18.3498  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 18/50\n",
      "----------\n",
      "Epoch: 18     train index of 5 minibatch: 1      time used: 3.523991346359253\n",
      "minibatch AVG loss: 15.67363166809082\n",
      "Epoch: 18     train index of 5 minibatch: 2      time used: 3.0728769302368164\n",
      "minibatch AVG loss: 19.09872169494629\n",
      "Epoch: 18     train index of 5 minibatch: 3      time used: 3.073007345199585\n",
      "minibatch AVG loss: 14.318334770202636\n",
      "\n",
      "Epoch: 18  train \n",
      "Loss: 16.9268  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 18  val \n",
      "Loss: 19.5483  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 19/50\n",
      "----------\n",
      "Epoch: 19     train index of 5 minibatch: 1      time used: 3.470515251159668\n",
      "minibatch AVG loss: 15.018668746948242\n",
      "Epoch: 19     train index of 5 minibatch: 2      time used: 3.0714073181152344\n",
      "minibatch AVG loss: 14.417611694335937\n",
      "Epoch: 19     train index of 5 minibatch: 3      time used: 3.0696067810058594\n",
      "minibatch AVG loss: 11.495877838134765\n",
      "\n",
      "Epoch: 19  train \n",
      "Loss: 13.7619  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 19  val \n",
      "Loss: 28.9725  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 20/50\n",
      "----------\n",
      "Epoch: 20     train index of 5 minibatch: 1      time used: 3.505648612976074\n",
      "minibatch AVG loss: 12.366493225097656\n",
      "Epoch: 20     train index of 5 minibatch: 2      time used: 3.0731709003448486\n",
      "minibatch AVG loss: 13.811698150634765\n",
      "Epoch: 20     train index of 5 minibatch: 3      time used: 3.0753424167633057\n",
      "minibatch AVG loss: 12.392133331298828\n",
      "\n",
      "Epoch: 20  train \n",
      "Loss: 13.7359  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 20  val \n",
      "Loss: 32.3972  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 21/50\n",
      "----------\n",
      "Epoch: 21     train index of 5 minibatch: 1      time used: 3.531909942626953\n",
      "minibatch AVG loss: 10.900207138061523\n",
      "Epoch: 21     train index of 5 minibatch: 2      time used: 3.0709424018859863\n",
      "minibatch AVG loss: 13.685499572753907\n",
      "Epoch: 21     train index of 5 minibatch: 3      time used: 3.0708556175231934\n",
      "minibatch AVG loss: 22.734128952026367\n",
      "\n",
      "Epoch: 21  train \n",
      "Loss: 16.9725  Acc: 98.5507\n",
      "benign precision: 96.7742  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 97.4359\n",
      "benign FPR: 2.5641  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 38.0\n",
      "benign FP: 1.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 97.4359\n",
      "malignant sensitivity: 97.4359  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 96.7742\n",
      "malignant TP: 38.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 21  val \n",
      "Loss: 16.4371  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 22/50\n",
      "----------\n",
      "Epoch: 22     train index of 5 minibatch: 1      time used: 3.5355193614959717\n",
      "minibatch AVG loss: 11.730533790588378\n",
      "Epoch: 22     train index of 5 minibatch: 2      time used: 3.0686721801757812\n",
      "minibatch AVG loss: 14.6068696975708\n",
      "Epoch: 22     train index of 5 minibatch: 3      time used: 3.0707573890686035\n",
      "minibatch AVG loss: 15.59112548828125\n",
      "\n",
      "Epoch: 22  train \n",
      "Loss: 14.1481  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 22  val \n",
      "Loss: 19.1773  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 23/50\n",
      "----------\n",
      "Epoch: 23     train index of 5 minibatch: 1      time used: 3.4814674854278564\n",
      "minibatch AVG loss: 17.26743927001953\n",
      "Epoch: 23     train index of 5 minibatch: 2      time used: 3.0738766193389893\n",
      "minibatch AVG loss: 16.357996940612793\n",
      "Epoch: 23     train index of 5 minibatch: 3      time used: 3.0713305473327637\n",
      "minibatch AVG loss: 9.992131900787353\n",
      "\n",
      "Epoch: 23  train \n",
      "Loss: 15.4215  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 23  val \n",
      "Loss: 33.5520  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 24/50\n",
      "----------\n",
      "Epoch: 24     train index of 5 minibatch: 1      time used: 3.499741554260254\n",
      "minibatch AVG loss: 14.871534729003907\n",
      "Epoch: 24     train index of 5 minibatch: 2      time used: 3.0705337524414062\n",
      "minibatch AVG loss: 17.88718433380127\n",
      "Epoch: 24     train index of 5 minibatch: 3      time used: 3.069218635559082\n",
      "minibatch AVG loss: 15.524066257476807\n",
      "\n",
      "Epoch: 24  train \n",
      "Loss: 16.4889  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 24  val \n",
      "Loss: 37.3752  Acc: 93.7500\n",
      "benign precision: 100.0000  recall: 85.7143\n",
      "benign sensitivity: 85.7143  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 90.0000\n",
      "benign TP: 6.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 1.0\n",
      "malignant precision: 90.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 85.7143\n",
      "malignant FPR: 14.2857  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 6.0\n",
      "malignant FP: 1.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 25/50\n",
      "----------\n",
      "Epoch: 25     train index of 5 minibatch: 1      time used: 3.491452217102051\n",
      "minibatch AVG loss: 14.31117000579834\n",
      "Epoch: 25     train index of 5 minibatch: 2      time used: 3.0708117485046387\n",
      "minibatch AVG loss: 14.71784610748291\n",
      "Epoch: 25     train index of 5 minibatch: 3      time used: 3.0718026161193848\n",
      "minibatch AVG loss: 14.731579399108886\n",
      "\n",
      "Epoch: 25  train \n",
      "Loss: 14.8883  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 25  val \n",
      "Loss: 20.1848  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 26/50\n",
      "----------\n",
      "Epoch: 26     train index of 5 minibatch: 1      time used: 3.500420570373535\n",
      "minibatch AVG loss: 13.643055725097657\n",
      "Epoch: 26     train index of 5 minibatch: 2      time used: 3.0722663402557373\n",
      "minibatch AVG loss: 13.940603256225586\n",
      "Epoch: 26     train index of 5 minibatch: 3      time used: 3.0739808082580566\n",
      "minibatch AVG loss: 11.582646560668945\n",
      "\n",
      "Epoch: 26  train \n",
      "Loss: 13.0891  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 26  val \n",
      "Loss: 30.2842  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 27/50\n",
      "----------\n",
      "Epoch: 27     train index of 5 minibatch: 1      time used: 3.5177061557769775\n",
      "minibatch AVG loss: 11.10955982208252\n",
      "Epoch: 27     train index of 5 minibatch: 2      time used: 3.0719189643859863\n",
      "minibatch AVG loss: 11.198120880126954\n",
      "Epoch: 27     train index of 5 minibatch: 3      time used: 3.0705080032348633\n",
      "minibatch AVG loss: 11.882708835601807\n",
      "\n",
      "Epoch: 27  train \n",
      "Loss: 12.0494  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 27  val \n",
      "Loss: 22.4955  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 28/50\n",
      "----------\n",
      "Epoch: 28     train index of 5 minibatch: 1      time used: 3.4880666732788086\n",
      "minibatch AVG loss: 12.421070194244384\n",
      "Epoch: 28     train index of 5 minibatch: 2      time used: 3.071887254714966\n",
      "minibatch AVG loss: 11.328839015960693\n",
      "Epoch: 28     train index of 5 minibatch: 3      time used: 3.07289981842041\n",
      "minibatch AVG loss: 11.178790473937989\n",
      "\n",
      "Epoch: 28  train \n",
      "Loss: 11.2860  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 28  val \n",
      "Loss: 20.3743  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 29/50\n",
      "----------\n",
      "Epoch: 29     train index of 5 minibatch: 1      time used: 3.485506296157837\n",
      "minibatch AVG loss: 11.432595443725585\n",
      "Epoch: 29     train index of 5 minibatch: 2      time used: 3.0683507919311523\n",
      "minibatch AVG loss: 11.248090934753417\n",
      "Epoch: 29     train index of 5 minibatch: 3      time used: 3.0701544284820557\n",
      "minibatch AVG loss: 9.419136810302735\n",
      "\n",
      "Epoch: 29  train \n",
      "Loss: 11.3355  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 29  val \n",
      "Loss: 22.4925  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 30/50\n",
      "----------\n",
      "Epoch: 30     train index of 5 minibatch: 1      time used: 3.507453441619873\n",
      "minibatch AVG loss: 12.58382511138916\n",
      "Epoch: 30     train index of 5 minibatch: 2      time used: 3.0714991092681885\n",
      "minibatch AVG loss: 12.275836944580078\n",
      "Epoch: 30     train index of 5 minibatch: 3      time used: 3.0722439289093018\n",
      "minibatch AVG loss: 12.14010066986084\n",
      "\n",
      "Epoch: 30  train \n",
      "Loss: 12.3232  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 30  val \n",
      "Loss: 24.9810  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 31/50\n",
      "----------\n",
      "Epoch: 31     train index of 5 minibatch: 1      time used: 3.505498170852661\n",
      "minibatch AVG loss: 13.610407829284668\n",
      "Epoch: 31     train index of 5 minibatch: 2      time used: 3.0707273483276367\n",
      "minibatch AVG loss: 6.006703948974609\n",
      "Epoch: 31     train index of 5 minibatch: 3      time used: 3.0698201656341553\n",
      "minibatch AVG loss: 11.871558380126952\n",
      "\n",
      "Epoch: 31  train \n",
      "Loss: 10.6306  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 31  val \n",
      "Loss: 23.0155  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 32/50\n",
      "----------\n",
      "Epoch: 32     train index of 5 minibatch: 1      time used: 3.50247859954834\n",
      "minibatch AVG loss: 10.013664245605469\n",
      "Epoch: 32     train index of 5 minibatch: 2      time used: 3.0734169483184814\n",
      "minibatch AVG loss: 9.405377388000488\n",
      "Epoch: 32     train index of 5 minibatch: 3      time used: 3.0734195709228516\n",
      "minibatch AVG loss: 8.807243156433106\n",
      "\n",
      "Epoch: 32  train \n",
      "Loss: 9.2458  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 32  val \n",
      "Loss: 27.5044  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 33/50\n",
      "----------\n",
      "Epoch: 33     train index of 5 minibatch: 1      time used: 3.4852328300476074\n",
      "minibatch AVG loss: 11.027844619750976\n",
      "Epoch: 33     train index of 5 minibatch: 2      time used: 3.0688397884368896\n",
      "minibatch AVG loss: 8.753874969482421\n",
      "Epoch: 33     train index of 5 minibatch: 3      time used: 3.071803569793701\n",
      "minibatch AVG loss: 12.118892669677734\n",
      "\n",
      "Epoch: 33  train \n",
      "Loss: 11.1439  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 33  val \n",
      "Loss: 23.9207  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 34/50\n",
      "----------\n",
      "Epoch: 34     train index of 5 minibatch: 1      time used: 3.516150712966919\n",
      "minibatch AVG loss: 8.6523606300354\n",
      "Epoch: 34     train index of 5 minibatch: 2      time used: 3.07429838180542\n",
      "minibatch AVG loss: 12.349720191955566\n",
      "Epoch: 34     train index of 5 minibatch: 3      time used: 3.071281909942627\n",
      "minibatch AVG loss: 10.70135726928711\n",
      "\n",
      "Epoch: 34  train \n",
      "Loss: 10.5876  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 34  val \n",
      "Loss: 23.9200  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 35/50\n",
      "----------\n",
      "Epoch: 35     train index of 5 minibatch: 1      time used: 3.4841363430023193\n",
      "minibatch AVG loss: 11.021131706237792\n",
      "Epoch: 35     train index of 5 minibatch: 2      time used: 3.071326494216919\n",
      "minibatch AVG loss: 11.23249921798706\n",
      "Epoch: 35     train index of 5 minibatch: 3      time used: 3.068242073059082\n",
      "minibatch AVG loss: 8.351990699768066\n",
      "\n",
      "Epoch: 35  train \n",
      "Loss: 10.5195  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 35  val \n",
      "Loss: 22.0303  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 36/50\n",
      "----------\n",
      "Epoch: 36     train index of 5 minibatch: 1      time used: 3.4795618057250977\n",
      "minibatch AVG loss: 10.710337352752685\n",
      "Epoch: 36     train index of 5 minibatch: 2      time used: 3.0705857276916504\n",
      "minibatch AVG loss: 12.80622091293335\n",
      "Epoch: 36     train index of 5 minibatch: 3      time used: 3.072277069091797\n",
      "minibatch AVG loss: 8.47322940826416\n",
      "\n",
      "Epoch: 36  train \n",
      "Loss: 10.3068  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 36  val \n",
      "Loss: 28.2325  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 37/50\n",
      "----------\n",
      "Epoch: 37     train index of 5 minibatch: 1      time used: 3.4714481830596924\n",
      "minibatch AVG loss: 13.02977123260498\n",
      "Epoch: 37     train index of 5 minibatch: 2      time used: 3.0709095001220703\n",
      "minibatch AVG loss: 6.096401405334473\n",
      "Epoch: 37     train index of 5 minibatch: 3      time used: 3.0711028575897217\n",
      "minibatch AVG loss: 11.321199417114258\n",
      "\n",
      "Epoch: 37  train \n",
      "Loss: 9.8688  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 37  val \n",
      "Loss: 24.8412  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 38/50\n",
      "----------\n",
      "Epoch: 38     train index of 5 minibatch: 1      time used: 3.495922327041626\n",
      "minibatch AVG loss: 8.28956117630005\n",
      "Epoch: 38     train index of 5 minibatch: 2      time used: 3.0733718872070312\n",
      "minibatch AVG loss: 9.75651044845581\n",
      "Epoch: 38     train index of 5 minibatch: 3      time used: 3.0711779594421387\n",
      "minibatch AVG loss: 11.438367748260498\n",
      "\n",
      "Epoch: 38  train \n",
      "Loss: 10.1133  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 38  val \n",
      "Loss: 27.0383  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 39/50\n",
      "----------\n",
      "Epoch: 39     train index of 5 minibatch: 1      time used: 3.4629268646240234\n",
      "minibatch AVG loss: 7.545141792297363\n",
      "Epoch: 39     train index of 5 minibatch: 2      time used: 3.071549892425537\n",
      "minibatch AVG loss: 10.594107913970948\n",
      "Epoch: 39     train index of 5 minibatch: 3      time used: 3.0703935623168945\n",
      "minibatch AVG loss: 9.389878082275391\n",
      "\n",
      "Epoch: 39  train \n",
      "Loss: 8.9736  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 39  val \n",
      "Loss: 20.8102  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 40/50\n",
      "----------\n",
      "Epoch: 40     train index of 5 minibatch: 1      time used: 3.488690137863159\n",
      "minibatch AVG loss: 6.9715110778808596\n",
      "Epoch: 40     train index of 5 minibatch: 2      time used: 3.0715489387512207\n",
      "minibatch AVG loss: 9.685385131835938\n",
      "Epoch: 40     train index of 5 minibatch: 3      time used: 3.073610305786133\n",
      "minibatch AVG loss: 8.001704216003418\n",
      "\n",
      "Epoch: 40  train \n",
      "Loss: 8.2631  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 40  val \n",
      "Loss: 23.7552  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 41/50\n",
      "----------\n",
      "Epoch: 41     train index of 5 minibatch: 1      time used: 3.5304439067840576\n",
      "minibatch AVG loss: 7.825724506378174\n",
      "Epoch: 41     train index of 5 minibatch: 2      time used: 3.0689706802368164\n",
      "minibatch AVG loss: 8.638400650024414\n",
      "Epoch: 41     train index of 5 minibatch: 3      time used: 3.0713279247283936\n",
      "minibatch AVG loss: 9.766884231567383\n",
      "\n",
      "Epoch: 41  train \n",
      "Loss: 8.8408  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 41  val \n",
      "Loss: 21.1962  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 42/50\n",
      "----------\n",
      "Epoch: 42     train index of 5 minibatch: 1      time used: 3.4908103942871094\n",
      "minibatch AVG loss: 10.593801879882813\n",
      "Epoch: 42     train index of 5 minibatch: 2      time used: 3.0757594108581543\n",
      "minibatch AVG loss: 8.741619968414307\n",
      "Epoch: 42     train index of 5 minibatch: 3      time used: 3.0731186866760254\n",
      "minibatch AVG loss: 9.823890495300294\n",
      "\n",
      "Epoch: 42  train \n",
      "Loss: 9.4045  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 42  val \n",
      "Loss: 23.3937  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 43/50\n",
      "----------\n",
      "Epoch: 43     train index of 5 minibatch: 1      time used: 3.4842216968536377\n",
      "minibatch AVG loss: 7.320515918731689\n",
      "Epoch: 43     train index of 5 minibatch: 2      time used: 3.070479393005371\n",
      "minibatch AVG loss: 12.34576358795166\n",
      "Epoch: 43     train index of 5 minibatch: 3      time used: 3.0703883171081543\n",
      "minibatch AVG loss: 7.230989074707031\n",
      "\n",
      "Epoch: 43  train \n",
      "Loss: 8.5520  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 43  val \n",
      "Loss: 24.6213  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 44/50\n",
      "----------\n",
      "Epoch: 44     train index of 5 minibatch: 1      time used: 3.5040359497070312\n",
      "minibatch AVG loss: 8.609432411193847\n",
      "Epoch: 44     train index of 5 minibatch: 2      time used: 3.073061466217041\n",
      "minibatch AVG loss: 7.254683923721314\n",
      "Epoch: 44     train index of 5 minibatch: 3      time used: 3.0735278129577637\n",
      "minibatch AVG loss: 9.650633907318115\n",
      "\n",
      "Epoch: 44  train \n",
      "Loss: 8.6261  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 44  val \n",
      "Loss: 25.1394  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 45/50\n",
      "----------\n",
      "Epoch: 45     train index of 5 minibatch: 1      time used: 3.4923434257507324\n",
      "minibatch AVG loss: 6.709775066375732\n",
      "Epoch: 45     train index of 5 minibatch: 2      time used: 3.070401906967163\n",
      "minibatch AVG loss: 12.272284317016602\n",
      "Epoch: 45     train index of 5 minibatch: 3      time used: 3.070176601409912\n",
      "minibatch AVG loss: 10.155961799621583\n",
      "\n",
      "Epoch: 45  train \n",
      "Loss: 9.4805  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 45  val \n",
      "Loss: 24.4942  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 46/50\n",
      "----------\n",
      "Epoch: 46     train index of 5 minibatch: 1      time used: 3.5090019702911377\n",
      "minibatch AVG loss: 8.84539361000061\n",
      "Epoch: 46     train index of 5 minibatch: 2      time used: 3.073310136795044\n",
      "minibatch AVG loss: 10.982228851318359\n",
      "Epoch: 46     train index of 5 minibatch: 3      time used: 3.07285737991333\n",
      "minibatch AVG loss: 8.081228065490723\n",
      "\n",
      "Epoch: 46  train \n",
      "Loss: 8.8343  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 46  val \n",
      "Loss: 22.0796  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 47/50\n",
      "----------\n",
      "Epoch: 47     train index of 5 minibatch: 1      time used: 3.4671432971954346\n",
      "minibatch AVG loss: 8.513541316986084\n",
      "Epoch: 47     train index of 5 minibatch: 2      time used: 3.069270372390747\n",
      "minibatch AVG loss: 6.835437297821045\n",
      "Epoch: 47     train index of 5 minibatch: 3      time used: 3.070443868637085\n",
      "minibatch AVG loss: 10.33354082107544\n",
      "\n",
      "Epoch: 47  train \n",
      "Loss: 8.2929  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 47  val \n",
      "Loss: 24.9055  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 48/50\n",
      "----------\n",
      "Epoch: 48     train index of 5 minibatch: 1      time used: 3.4993832111358643\n",
      "minibatch AVG loss: 7.012808895111084\n",
      "Epoch: 48     train index of 5 minibatch: 2      time used: 3.0750975608825684\n",
      "minibatch AVG loss: 8.241594982147216\n",
      "Epoch: 48     train index of 5 minibatch: 3      time used: 3.07338547706604\n",
      "minibatch AVG loss: 13.049099540710449\n",
      "\n",
      "Epoch: 48  train \n",
      "Loss: 9.1117  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 48  val \n",
      "Loss: 22.8782  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 49/50\n",
      "----------\n",
      "Epoch: 49     train index of 5 minibatch: 1      time used: 3.4728055000305176\n",
      "minibatch AVG loss: 7.990491676330566\n",
      "Epoch: 49     train index of 5 minibatch: 2      time used: 3.070349931716919\n",
      "minibatch AVG loss: 10.10118236541748\n",
      "Epoch: 49     train index of 5 minibatch: 3      time used: 3.0699613094329834\n",
      "minibatch AVG loss: 7.484938716888427\n",
      "\n",
      "Epoch: 49  train \n",
      "Loss: 8.4129  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 49  val \n",
      "Loss: 22.0348  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 50/50\n",
      "----------\n",
      "Epoch: 50     train index of 5 minibatch: 1      time used: 3.509450912475586\n",
      "minibatch AVG loss: 8.271012210845948\n",
      "Epoch: 50     train index of 5 minibatch: 2      time used: 3.0726351737976074\n",
      "minibatch AVG loss: 10.776511764526367\n",
      "Epoch: 50     train index of 5 minibatch: 3      time used: 3.0753328800201416\n",
      "minibatch AVG loss: 6.680179309844971\n",
      "\n",
      "Epoch: 50  train \n",
      "Loss: 8.7751  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 30.0\n",
      "benign TN: 39.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 39.0\n",
      "malignant TN: 30.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 50  val \n",
      "Loss: 23.6100  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 7.0\n",
      "benign TN: 9.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 9.0\n",
      "malignant TN: 7.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Training complete in 10m 10s\n",
      "Best epoch idx:  50\n",
      "Best epoch train Acc: 100.000000\n",
      "Best epoch val Acc: 100.000000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "model trained by GPU (idx:0) has been saved at  /home/MIL_Experiment/saved_models/MIL_ViT_384_401_PT_lf05_b4_p32_warwick_MIL.pth\n"
     ]
    }
   ],
   "source": [
    "!python MIL_train.py --model_idx ViT_384_401_PT_lf05_b4_p32_warwick_MIL --data_augmentation_mode 2 --edge_size 384 --batch_size 4 --patch_size 32 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_MIL --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLy5OE1kOq3W"
   },
   "source": [
    "* MIL Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IxmTlFRIV4lu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153464968,
     "user_tz": -480,
     "elapsed": 11727,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "c2d4e67d-5479-4588-e9d6-2e59f16e29b4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*********************************setting*************************************\n",
      "Namespace(CLS_MIL_head_weight=1.0, CLS_MIL_off=False, MIL_Stripe=False, MIL_head_weight=1.0, Pre_Trained_model_path=None, batch_size=1, check_minibatch=5, data_augmentation_mode=2, dataroot='/data/MIL_Experiment/dataset/warwick_MIL', draw_root='/home/MIL_Experiment/runs', edge_size=384, enable_attention_check=False, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ViT_384_401_PT_lf05_b4_p32_warwick_MIL', model_path='/home/MIL_Experiment/saved_models', paint=True, patch_size=32, shuffle_MIL_off=False, shuffle_attention_check=False, shuffle_dataloader=False)\n",
      "GPU: 0\n",
      "model loaded\n",
      "model : ViT_384_401_PT_lf05_b4_p32_warwick_MIL\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 0.38190603256225586\n",
      "minibatch AVG loss: 22.55486993789673\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 0.2689328193664551\n",
      "minibatch AVG loss: 14.458586025238038\n",
      "Epoch: test     test index of 5 minibatch: 3      time used: 0.26836204528808594\n",
      "minibatch AVG loss: 7.832994437217712\n",
      "Epoch: test     test index of 5 minibatch: 4      time used: 0.26810121536254883\n",
      "minibatch AVG loss: 14.030884933471679\n",
      "Epoch: test     test index of 5 minibatch: 5      time used: 0.26595473289489746\n",
      "minibatch AVG loss: 28.057773113250732\n",
      "Epoch: test     test index of 5 minibatch: 6      time used: 0.26641035079956055\n",
      "minibatch AVG loss: 12.287438678741456\n",
      "Epoch: test     test index of 5 minibatch: 7      time used: 0.26689600944519043\n",
      "minibatch AVG loss: 24.58982925415039\n",
      "Epoch: test     test index of 5 minibatch: 8      time used: 0.26833581924438477\n",
      "minibatch AVG loss: 26.788585090637206\n",
      "Epoch: test     test index of 5 minibatch: 9      time used: 0.2698824405670166\n",
      "minibatch AVG loss: 16.587738037109375\n",
      "Epoch: test     test index of 5 minibatch: 10      time used: 0.2692413330078125\n",
      "minibatch AVG loss: 31.178875541687013\n",
      "Epoch: test     test index of 5 minibatch: 11      time used: 0.2676699161529541\n",
      "minibatch AVG loss: 40.628502655029294\n",
      "Epoch: test     test index of 5 minibatch: 12      time used: 0.26743125915527344\n",
      "minibatch AVG loss: 24.116844940185548\n",
      "Epoch: test     test index of 5 minibatch: 13      time used: 0.26755189895629883\n",
      "minibatch AVG loss: 12.761226701736451\n",
      "Epoch: test     test index of 5 minibatch: 14      time used: 0.2664785385131836\n",
      "minibatch AVG loss: 21.279768180847167\n",
      "Epoch: test     test index of 5 minibatch: 15      time used: 0.2698969841003418\n",
      "minibatch AVG loss: 27.55272493362427\n",
      "Epoch: test     test index of 5 minibatch: 16      time used: 0.2686772346496582\n",
      "minibatch AVG loss: 25.356864547729494\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 21.8790  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 37.0\n",
      "benign TN: 43.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 43.0\n",
      "malignant TN: 37.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 4s\n"
     ]
    }
   ],
   "source": [
    "!python MIL_test.py --model_idx ViT_384_401_PT_lf05_b4_p32_warwick_MIL --data_augmentation_mode 2 --edge_size 384 --batch_size 1 --patch_size 32  --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_MIL --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dypseRcOtHU"
   },
   "source": [
    "# Test & Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS1jyFoHSeih"
   },
   "source": [
    "Basic CLS CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "v5WbvtSpZXyC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153499911,
     "user_tz": -480,
     "elapsed": 34948,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "71fa69e5-144f-4af0-f457-5e25199f4c8e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "class_names: ['benign', 'malignant']\n",
      "model loaded\n",
      "model : ViT_384_401_PT_lf05_b4_p32_warwick_MIL\n",
      "*********************************setting*************************************\n",
      "Namespace(MIL_Stripe=True, att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=5, cls_token_off=False, data_augmentation_mode=2, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ViT_384_401_PT_lf05_b4_p32_warwick_MIL', model_path='/home/MIL_Experiment/saved_models', num_classes=0, paint=True, pos_embedding_off=False)\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 0.219343900680542\n",
      "minibatch AVG loss: 0.006079076018068008\n",
      "/home/MIL_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return sof(x)\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 0.13436365127563477\n",
      "minibatch AVG loss: 9.85561688139569e-05\n",
      "Epoch: test     test index of 5 minibatch: 3      time used: 0.1336362361907959\n",
      "minibatch AVG loss: 0.00024796624929876996\n",
      "Epoch: test     test index of 5 minibatch: 4      time used: 0.13492870330810547\n",
      "minibatch AVG loss: 0.0009635813723434695\n",
      "Epoch: test     test index of 5 minibatch: 5      time used: 0.13463568687438965\n",
      "minibatch AVG loss: 0.0007488142364309169\n",
      "Epoch: test     test index of 5 minibatch: 6      time used: 0.13428997993469238\n",
      "minibatch AVG loss: 0.0001113576683565043\n",
      "Epoch: test     test index of 5 minibatch: 7      time used: 0.1336665153503418\n",
      "minibatch AVG loss: 0.00952209360548295\n",
      "Epoch: test     test index of 5 minibatch: 8      time used: 0.13640093803405762\n",
      "minibatch AVG loss: 0.00014474831987172366\n",
      "Epoch: test     test index of 5 minibatch: 9      time used: 0.1358020305633545\n",
      "minibatch AVG loss: 0.0004034592639072798\n",
      "Epoch: test     test index of 5 minibatch: 10      time used: 0.13613653182983398\n",
      "minibatch AVG loss: 0.0007183284169514081\n",
      "Epoch: test     test index of 5 minibatch: 11      time used: 0.13370084762573242\n",
      "minibatch AVG loss: 0.0006708791595883667\n",
      "Epoch: test     test index of 5 minibatch: 12      time used: 0.13431811332702637\n",
      "minibatch AVG loss: 0.00031087875977391376\n",
      "Epoch: test     test index of 5 minibatch: 13      time used: 0.13488101959228516\n",
      "minibatch AVG loss: 0.0002302776734723011\n",
      "Epoch: test     test index of 5 minibatch: 14      time used: 0.13517475128173828\n",
      "minibatch AVG loss: 0.002118440079357242\n",
      "Epoch: test     test index of 5 minibatch: 15      time used: 0.13313817977905273\n",
      "minibatch AVG loss: 0.00013349815708352253\n",
      "Epoch: test     test index of 5 minibatch: 16      time used: 0.1324625015258789\n",
      "minibatch AVG loss: 9.281057173211593e-05\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 0.0014  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 37.0\n",
      "benign TN: 43.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 43.0\n",
      "malignant TN: 37.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 28s\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx ViT_384_401_PT_lf05_b4_p32_warwick_MIL --data_augmentation_mode 2 --MIL_Stripe --enable_attention_check --check_minibatch 5 --edge_size 384 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/imaging_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zySxjXSgSg82"
   },
   "source": [
    "CAM on shuffled images (random batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VrEyVWowSRPR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153517705,
     "user_tz": -480,
     "elapsed": 17800,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "96602656-2595-4e25-c54c-a1e1a5fc3fd6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*********************************setting*************************************\n",
      "Namespace(CLS_MIL_head_weight=1.0, CLS_MIL_off=False, MIL_Stripe=True, MIL_head_weight=1.0, Pre_Trained_model_path=None, batch_size=4, check_minibatch=5, data_augmentation_mode=2, dataroot='/data/MIL_Experiment/dataset/warwick_MIL', draw_root='/home/MIL_Experiment/imaging_results', edge_size=384, enable_attention_check=False, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ViT_384_401_PT_lf05_b4_p32_warwick_MIL', model_path='/home/MIL_Experiment/saved_models', paint=True, patch_size=32, shuffle_MIL_off=False, shuffle_attention_check=True, shuffle_dataloader=True)\n",
      "GPU: 0\n",
      "model loaded\n",
      "model : ViT_384_401_PT_lf05_b4_p32_warwick_MIL\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 0.714881181716919\n",
      "minibatch AVG loss: 0.0007411651415168308\n",
      "/home/MIL_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return sof(x)\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 0.48929452896118164\n",
      "minibatch AVG loss: 0.0006197053662617691\n",
      "Epoch: test     test index of 5 minibatch: 3      time used: 0.48827028274536133\n",
      "minibatch AVG loss: 0.0027464380575111134\n",
      "Epoch: test     test index of 5 minibatch: 4      time used: 0.48871636390686035\n",
      "minibatch AVG loss: 0.0022484117740532382\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 0.0016  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 37.0\n",
      "benign TN: 43.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 43.0\n",
      "malignant TN: 37.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 11s\n"
     ]
    }
   ],
   "source": [
    "!python MIL_test.py --model_idx ViT_384_401_PT_lf05_b4_p32_warwick_MIL --data_augmentation_mode 2 --shuffle_attention_check --MIL_Stripe --edge_size 384 --shuffle_dataloader --batch_size 4 --patch_size 32 --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_MIL --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/imaging_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuGZrdkvSsql"
   },
   "source": [
    "CAM on shuffled images (continuous batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0jWUVs29S6ZR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153535628,
     "user_tz": -480,
     "elapsed": 17927,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "04f50b77-abab-4108-ff26-b40fd43f6bd9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*********************************setting*************************************\n",
      "Namespace(CLS_MIL_head_weight=1.0, CLS_MIL_off=False, MIL_Stripe=True, MIL_head_weight=1.0, Pre_Trained_model_path=None, batch_size=4, check_minibatch=5, data_augmentation_mode=2, dataroot='/data/MIL_Experiment/dataset/warwick_MIL', draw_root='/home/MIL_Experiment/imaging_results', edge_size=384, enable_attention_check=False, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ViT_384_401_PT_lf05_b4_p32_warwick_MIL', model_path='/home/MIL_Experiment/saved_models', paint=True, patch_size=32, shuffle_MIL_off=False, shuffle_attention_check=True, shuffle_dataloader=False)\n",
      "GPU: 0\n",
      "model loaded\n",
      "model : ViT_384_401_PT_lf05_b4_p32_warwick_MIL\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 0.6896839141845703\n",
      "minibatch AVG loss: 0.00233862758759642\n",
      "/home/MIL_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return sof(x)\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 0.48767590522766113\n",
      "minibatch AVG loss: 0.002796845347620547\n",
      "Epoch: test     test index of 5 minibatch: 3      time used: 0.4885842800140381\n",
      "minibatch AVG loss: 0.0005072548112366349\n",
      "Epoch: test     test index of 5 minibatch: 4      time used: 0.4865288734436035\n",
      "minibatch AVG loss: 0.0007129925521439873\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 0.0016  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 37.0\n",
      "benign TN: 43.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 43.0\n",
      "malignant TN: 37.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 11s\n"
     ]
    }
   ],
   "source": [
    "!python MIL_test.py --model_idx ViT_384_401_PT_lf05_b4_p32_warwick_MIL --data_augmentation_mode 2 --shuffle_attention_check --MIL_Stripe --edge_size 384 --batch_size 4 --patch_size 32 --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_MIL --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/imaging_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCmllSS8TAnD"
   },
   "source": [
    "CAM on shuffled images (batch size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9KcJHlZkTHHI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153570578,
     "user_tz": -480,
     "elapsed": 34954,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "46eb2cdb-c25f-4bd2-8cdd-8e566ac02e1c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*********************************setting*************************************\n",
      "Namespace(CLS_MIL_head_weight=1.0, CLS_MIL_off=False, MIL_Stripe=True, MIL_head_weight=1.0, Pre_Trained_model_path=None, batch_size=1, check_minibatch=5, data_augmentation_mode=2, dataroot='/data/MIL_Experiment/dataset/warwick_MIL', draw_root='/home/MIL_Experiment/imaging_results', edge_size=384, enable_attention_check=False, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ViT_384_401_PT_lf05_b4_p32_warwick_MIL', model_path='/home/MIL_Experiment/saved_models', paint=True, patch_size=32, shuffle_MIL_off=False, shuffle_attention_check=True, shuffle_dataloader=False)\n",
      "GPU: 0\n",
      "model loaded\n",
      "model : ViT_384_401_PT_lf05_b4_p32_warwick_MIL\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 0.23102664947509766\n",
      "minibatch AVG loss: 0.008047467746655457\n",
      "/home/MIL_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return sof(x)\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 0.13775038719177246\n",
      "minibatch AVG loss: 9.867522530839778e-05\n",
      "Epoch: test     test index of 5 minibatch: 3      time used: 0.13932442665100098\n",
      "minibatch AVG loss: 0.00022537110489793122\n",
      "Epoch: test     test index of 5 minibatch: 4      time used: 0.1381075382232666\n",
      "minibatch AVG loss: 0.000982997877872549\n",
      "Epoch: test     test index of 5 minibatch: 5      time used: 0.1400303840637207\n",
      "minibatch AVG loss: 0.0006221464776899665\n",
      "Epoch: test     test index of 5 minibatch: 6      time used: 0.13991475105285645\n",
      "minibatch AVG loss: 0.00010282335279043764\n",
      "Epoch: test     test index of 5 minibatch: 7      time used: 0.14027810096740723\n",
      "minibatch AVG loss: 0.010312493698438629\n",
      "Epoch: test     test index of 5 minibatch: 8      time used: 0.14136123657226562\n",
      "minibatch AVG loss: 0.00014984984809416347\n",
      "Epoch: test     test index of 5 minibatch: 9      time used: 0.14183831214904785\n",
      "minibatch AVG loss: 0.0004075907083461061\n",
      "Epoch: test     test index of 5 minibatch: 10      time used: 0.13892316818237305\n",
      "minibatch AVG loss: 0.0006339335857774131\n",
      "Epoch: test     test index of 5 minibatch: 11      time used: 0.13773894309997559\n",
      "minibatch AVG loss: 0.0006431476242141799\n",
      "Epoch: test     test index of 5 minibatch: 12      time used: 0.13940644264221191\n",
      "minibatch AVG loss: 0.00034434734407113866\n",
      "Epoch: test     test index of 5 minibatch: 13      time used: 0.13883018493652344\n",
      "minibatch AVG loss: 0.000250867600334459\n",
      "Epoch: test     test index of 5 minibatch: 14      time used: 0.13839244842529297\n",
      "minibatch AVG loss: 0.0023376804158033336\n",
      "Epoch: test     test index of 5 minibatch: 15      time used: 0.13862299919128418\n",
      "minibatch AVG loss: 0.00015251850854838266\n",
      "Epoch: test     test index of 5 minibatch: 16      time used: 0.14023590087890625\n",
      "minibatch AVG loss: 0.00011090383122791536\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 0.0016  Acc: 100.0000\n",
      "benign precision: 100.0000  recall: 100.0000\n",
      "benign sensitivity: 100.0000  specificity: 100.0000\n",
      "benign FPR: 0.0000  NPV: 100.0000\n",
      "benign TP: 37.0\n",
      "benign TN: 43.0\n",
      "benign FP: 0.0\n",
      "benign FN: 0.0\n",
      "malignant precision: 100.0000  recall: 100.0000\n",
      "malignant sensitivity: 100.0000  specificity: 100.0000\n",
      "malignant FPR: 0.0000  NPV: 100.0000\n",
      "malignant TP: 43.0\n",
      "malignant TN: 37.0\n",
      "malignant FP: 0.0\n",
      "malignant FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 28s\n"
     ]
    }
   ],
   "source": [
    "!python MIL_test.py --model_idx ViT_384_401_PT_lf05_b4_p32_warwick_MIL --data_augmentation_mode 2 --shuffle_attention_check --MIL_Stripe --edge_size 384 --batch_size 1 --patch_size 32 --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_MIL --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/imaging_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32lV43PnKVJx"
   },
   "source": [
    "# Synchronize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mCZDUffdQep4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153570579,
     "user_tz": -480,
     "elapsed": 6,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    }
   },
   "outputs": [],
   "source": [
    "# change working dir\n",
    "import os\n",
    "os.chdir(\"/home/MIL_Experiment/code/utils\")\n",
    "!python check_log_json.py --draw_root /home/MIL_Experiment/runs --record_dir /home/MIL_Experiment/CSV_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_Wx0ymiiEuyS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153583031,
     "user_tz": -480,
     "elapsed": 12456,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "85cd3e1a-14a3-4dfa-b6e4-7ac261dc8d6e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "results copy completed!\n"
     ]
    }
   ],
   "source": [
    "# create path on google drive\n",
    "!mkdir /content/drive/MyDrive/MIL_SI_sample\n",
    "# copy the results\n",
    "!/bin/cp -rf /home/MIL_Experiment/* /content/drive/MyDrive/MIL_SI_sample/\n",
    "print('results copy completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9lzAtLIhnGe5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651153583032,
     "user_tz": -480,
     "elapsed": 21,
     "user": {
      "displayName": "Rush MSHT",
      "userId": "17678018738220178064"
     }
    },
    "outputId": "f119ebd5-1d24-4c3f-89c3-8bcde9b14df6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Apr 28 21:46:22 UTC 2022\n"
     ]
    }
   ],
   "source": [
    "!date --date='+8 hour'  # CST time zone"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "OpenSourse Sample MIL warwick_Experiment 384 401 lf05 p32 MIL Train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}